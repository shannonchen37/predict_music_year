{"cells":[{"cell_type":"code","execution_count":34,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['year_prediction.csv']\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import matplotlib.pyplot as plt # data visualisation\n","import tensorflow as tf\n","\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n","\n","import os\n","print(os.listdir(\"../input\"))\n","\n","# Any results you write to the current directory are saved as output."]},{"cell_type":"code","execution_count":35,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["data = pd.read_csv(\"../input/year_prediction.csv\")\n","data = data.rename(index=str, columns={\"label\":\"year\"})"]},{"cell_type":"markdown","metadata":{},"source":["We plot a histogram to understand how evenly spread the data is by viewing number of songs we have for a given year."]},{"cell_type":"code","execution_count":36,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["Text(0, 0.5, 'Number of songs')"]},"execution_count":36,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAk0AAAGwCAYAAAC0HlECAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABD2ElEQVR4nO3de1xVdb7/8TeggKgb0wTkJ16KRkXFCybtLo4lIxrTT0fPjJWnTEnTA6XQeGHGyLGZn+bkrZFyZkqx38nxUtmMYiDhLRNvKMdr5DXs6IZKZaspCKzfHx3Wzx1qayvIVl/Px2M9xrXWZ6/9WXvNbN7zXZftZRiGIQAAAFyTd103AAAAcCsgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAAL6tV1A7eLyspKnThxQo0bN5aXl1ddtwMAACwwDENnz55VaGiovL2vPZZEaKohJ06cUFhYWF23AQAArsPx48fVsmXLa9YQmmpI48aNJf3wodtstjruBgAAWOF0OhUWFmb+Hb8WQlMNqTolZ7PZCE0AANxirFxaw4XgAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAKPCU3Tp0+Xl5eXxo0bZy67ePGiEhIS1KxZMzVq1EiDBw9WUVGRy+sKCwsVFxengIAABQUFafz48SovL3epWb9+vbp37y4/Pz+Fh4crPT292vunpaWpTZs28vf3V3R0tLZt21YbuwkAAG5RHhGatm/frr/+9a+KjIx0WZ6UlKSVK1dq+fLl2rBhg06cOKFBgwaZ6ysqKhQXF6eysjJt3rxZixYtUnp6ulJTU82ao0ePKi4uTo8++qjy8/M1btw4Pf/888rKyjJrli5dquTkZL366qvauXOnunTpotjYWBUXF9f+zgMAgFuDUcfOnj1r3HfffUZ2drbx85//3Bg7dqxhGIZx5swZo379+sby5cvN2gMHDhiSjNzcXMMwDGP16tWGt7e34XA4zJq3337bsNlsRmlpqWEYhjFhwgSjY8eOLu85ZMgQIzY21pzv2bOnkZCQYM5XVFQYoaGhxrRp067a98WLF42SkhJzOn78uCHJKCkpuf4PAwAA3FQlJSWW/37X+UhTQkKC4uLiFBMT47I8Ly9Ply5dclnevn17tWrVSrm5uZKk3Nxcde7cWcHBwWZNbGysnE6n9u3bZ9b8eNuxsbHmNsrKypSXl+dS4+3trZiYGLPmSqZNm6bAwEBz4nfnAAC4vdVpaFqyZIl27typadOmVVvncDjk6+urJk2auCwPDg6Ww+Eway4PTFXrq9Zdq8bpdOrChQv69ttvVVFRccWaqm1cSUpKikpKSszp+PHj1nYaAADckurst+eOHz+usWPHKjs7W/7+/nXVxnXz8/OTn59fXbcBAABukjobacrLy1NxcbG6d++uevXqqV69etqwYYPefPNN1atXT8HBwSorK9OZM2dcXldUVKSQkBBJUkhISLW76armf6rGZrOpQYMGuvvuu+Xj43PFmqptAAAA1Flo6tOnj/bs2aP8/Hxz6tGjh4YOHWr+u379+srJyTFfU1BQoMLCQtntdkmS3W7Xnj17XO5yy87Ols1mU0REhFlz+Taqaqq24evrq6ioKJeayspK5eTkmDUAAAB1dnqucePG6tSpk8uyhg0bqlmzZuby+Ph4JScnq2nTprLZbHrxxRdlt9v1wAMPSJL69u2riIgIPfPMM5oxY4YcDocmT56shIQE89TZ6NGjNW/ePE2YMEEjRozQ2rVrtWzZMmVkZJjvm5ycrGHDhqlHjx7q2bOn5syZo/Pnz2v48OE36dMAAACers5CkxWzZ8+Wt7e3Bg8erNLSUsXGxuqtt94y1/v4+GjVqlUaM2aM7Ha7GjZsqGHDhmnq1KlmTdu2bZWRkaGkpCTNnTtXLVu21DvvvKPY2FizZsiQIfrmm2+Umpoqh8Ohrl27KjMzs9rF4QAAwLo2kzJc5o9Nj6ujTmqGl2EYRl03cTtwOp0KDAxUSUmJbDZbXbcDAECduxVCkzt/v+v8OU0AAAC3AkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhQr64bAAAAt742kzJc5o9Nj6ujTmoPI00AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACyo09D09ttvKzIyUjabTTabTXa7XZ988om5vnfv3vLy8nKZRo8e7bKNwsJCxcXFKSAgQEFBQRo/frzKy8tdatavX6/u3bvLz89P4eHhSk9Pr9ZLWlqa2rRpI39/f0VHR2vbtm21ss8AAODWVKehqWXLlpo+fbry8vK0Y8cOPfbYYxowYID27dtn1owcOVInT540pxkzZpjrKioqFBcXp7KyMm3evFmLFi1Senq6UlNTzZqjR48qLi5Ojz76qPLz8zVu3Dg9//zzysrKMmuWLl2q5ORkvfrqq9q5c6e6dOmi2NhYFRcX35wPAgAAeDwvwzCMum7ick2bNtWf//xnxcfHq3fv3uratavmzJlzxdpPPvlEv/zlL3XixAkFBwdLkubPn6+JEyfqm2++ka+vryZOnKiMjAzt3bvXfN2TTz6pM2fOKDMzU5IUHR2t+++/X/PmzZMkVVZWKiwsTC+++KImTZpkqW+n06nAwECVlJTIZrPdwCcAAMCtp82kDJf5Y9PjrrjM07jz99tjrmmqqKjQkiVLdP78edntdnP5+++/r7vvvludOnVSSkqKvv/+e3Ndbm6uOnfubAYmSYqNjZXT6TRHq3JzcxUTE+PyXrGxscrNzZUklZWVKS8vz6XG29tbMTExZs2VlJaWyul0ukwAAOD2Va+uG9izZ4/sdrsuXryoRo0aacWKFYqIiJAkPf3002rdurVCQ0O1e/duTZw4UQUFBfroo48kSQ6HwyUwSTLnHQ7HNWucTqcuXLig06dPq6Ki4oo1X3zxxVX7njZtmv7whz/c2M4DAHALuhVGkGpDnYemdu3aKT8/XyUlJfrggw80bNgwbdiwQRERERo1apRZ17lzZ7Vo0UJ9+vTR4cOHde+999Zh11JKSoqSk5PNeafTqbCwsDrsCAAA1KY6D02+vr4KDw+XJEVFRWn79u2aO3eu/vrXv1arjY6OliQdOnRI9957r0JCQqrd5VZUVCRJCgkJMf+zatnlNTabTQ0aNJCPj498fHyuWFO1jSvx8/OTn5+fm3sLAMCd7VYepfKYa5qqVFZWqrS09Irr8vPzJUktWrSQJNntdu3Zs8flLrfs7GzZbDbzFJ/dbldOTo7LdrKzs83rpnx9fRUVFeVSU1lZqZycHJdrqwAAwJ2tTkeaUlJS1L9/f7Vq1Upnz57V4sWLtX79emVlZenw4cNavHixHn/8cTVr1ky7d+9WUlKSevXqpcjISElS3759FRERoWeeeUYzZsyQw+HQ5MmTlZCQYI4CjR49WvPmzdOECRM0YsQIrV27VsuWLVNGxv9PusnJyRo2bJh69Oihnj17as6cOTp//ryGDx9eJ58LAADwPHUamoqLi/Xss8/q5MmTCgwMVGRkpLKysvSLX/xCx48f16effmoGmLCwMA0ePFiTJ082X+/j46NVq1ZpzJgxstvtatiwoYYNG6apU6eaNW3btlVGRoaSkpI0d+5ctWzZUu+8845iY2PNmiFDhuibb75RamqqHA6HunbtqszMzGoXhwMAgDtXnYamd99996rrwsLCtGHDhp/cRuvWrbV69epr1vTu3Vu7du26Zk1iYqISExN/8v0AAMCdyeOuaQIAAPBEhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsqFfXDQAAgDtbm0kZ1ZYdmx5XB51cGyNNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYEGdhqa3335bkZGRstlsstlsstvt+uSTT8z1Fy9eVEJCgpo1a6ZGjRpp8ODBKioqctlGYWGh4uLiFBAQoKCgII0fP17l5eUuNevXr1f37t3l5+en8PBwpaenV+slLS1Nbdq0kb+/v6Kjo7Vt27Za2WcAAHBrqtPQ1LJlS02fPl15eXnasWOHHnvsMQ0YMED79u2TJCUlJWnlypVavny5NmzYoBMnTmjQoEHm6ysqKhQXF6eysjJt3rxZixYtUnp6ulJTU82ao0ePKi4uTo8++qjy8/M1btw4Pf/888rKyjJrli5dquTkZL366qvauXOnunTpotjYWBUXF9+8DwMAAHi0Og1NTzzxhB5//HHdd999+tnPfqY//elPatSokbZs2aKSkhK9++67mjVrlh577DFFRUVp4cKF2rx5s7Zs2SJJWrNmjfbv36///M//VNeuXdW/f3+99tprSktLU1lZmSRp/vz5atu2rWbOnKkOHTooMTFR//Zv/6bZs2ebfcyaNUsjR47U8OHDFRERofnz5ysgIEALFiyok88FAAB4Ho+5pqmiokJLlizR+fPnZbfblZeXp0uXLikmJsasad++vVq1aqXc3FxJUm5urjp37qzg4GCzJjY2Vk6n0xytys3NddlGVU3VNsrKypSXl+dS4+3trZiYGLPmSkpLS+V0Ol0mAABw+6rz0LRnzx41atRIfn5+Gj16tFasWKGIiAg5HA75+vqqSZMmLvXBwcFyOBySJIfD4RKYqtZXrbtWjdPp1IULF/Ttt9+qoqLiijVV27iSadOmKTAw0JzCwsKua/8BAMCtoc5DU7t27ZSfn6+tW7dqzJgxGjZsmPbv31/Xbf2klJQUlZSUmNPx48fruiUAAFCL6vy353x9fRUeHi5JioqK0vbt2zV37lwNGTJEZWVlOnPmjMtoU1FRkUJCQiRJISEh1e5yq7q77vKaH99xV1RUJJvNpgYNGsjHx0c+Pj5XrKnaxpX4+fnJz8/v+nYaAADccup8pOnHKisrVVpaqqioKNWvX185OTnmuoKCAhUWFsput0uS7Ha79uzZ43KXW3Z2tmw2myIiIsyay7dRVVO1DV9fX0VFRbnUVFZWKicnx6wBAOBO1WZShst0J6vTkaaUlBT1799frVq10tmzZ7V48WKtX79eWVlZCgwMVHx8vJKTk9W0aVPZbDa9+OKLstvteuCBByRJffv2VUREhJ555hnNmDFDDodDkydPVkJCgjkKNHr0aM2bN08TJkzQiBEjtHbtWi1btkwZGf//wCcnJ2vYsGHq0aOHevbsqTlz5uj8+fMaPnx4nXwuAADA89RpaCouLtazzz6rkydPKjAwUJGRkcrKytIvfvELSdLs2bPl7e2twYMHq7S0VLGxsXrrrbfM1/v4+GjVqlUaM2aM7Ha7GjZsqGHDhmnq1KlmTdu2bZWRkaGkpCTNnTtXLVu21DvvvKPY2FizZsiQIfrmm2+Umpoqh8Ohrl27KjMzs9rF4QAA4M5Vp6Hp3XffveZ6f39/paWlKS0t7ao1rVu31urVq6+5nd69e2vXrl3XrElMTFRiYuI1awAAwJ3L465pAgAA8ESEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAgnp13QAAAPAMbSZluMwfmx5XR514JkaaAAAALCA0AQAAWOB2aNq5c6f27Nljzv/zn//UwIED9bvf/U5lZWU12hwAAICncDs0vfDCC/ryyy8lSUeOHNGTTz6pgIAALV++XBMmTKjxBgEAADyB26Hpyy+/VNeuXSVJy5cvV69evbR48WKlp6frww8/rOn+AAAAPILbockwDFVWVkqSPv30Uz3++OOSpLCwMH377bc12x0AAICHcDs09ejRQ3/84x/1f//v/9WGDRsUF/fD7YhHjx5VcHBwjTcIAADgCdwOTXPmzNHOnTuVmJio3//+9woPD5ckffDBB3rwwQdrvEEAAABP4PbDLSMjI13unqvy5z//WT4+PjXSFAAAgKepsSeC+/v719SmAAAAPI7boemuu+6Sl5dXteVeXl7y9/dXeHi4nnvuOQ0fPrxGGgQAAPAEboem1NRU/elPf1L//v3Vs2dPSdK2bduUmZmphIQEHT16VGPGjFF5eblGjhxZ4w0DAADUBbdD06ZNm/THP/5Ro0ePdln+17/+VWvWrNGHH36oyMhIvfnmm4QmAABw23D77rmsrCzFxMRUW96nTx9lZWVJkh5//HEdOXLkxrsDAADwEG6HpqZNm2rlypXVlq9cuVJNmzaVJJ0/f16NGze+8e4AAAA8hNun51555RWNGTNG69atM69p2r59u1avXq358+dLkrKzs/Xzn/+8ZjsFAACoQ26HppEjRyoiIkLz5s3TRx99JElq166dNmzYYD7c8uWXX67ZLgEAAOqY26fnJOmhhx7SP/7xD+3cuVM7d+7UP/7xj+t6Gvi0adN0//33q3HjxgoKCtLAgQNVUFDgUtO7d295eXm5TD++CL2wsFBxcXEKCAhQUFCQxo8fr/Lycpea9evXq3v37vLz81N4eLjS09Or9ZOWlqY2bdrI399f0dHR2rZtm9v7BAAAbk/X9XDLyspKHTp0SMXFxeaP91bp1auX5e1s2LBBCQkJuv/++1VeXq7f/e536tu3r/bv36+GDRuadSNHjtTUqVPN+YCAAPPfFRUViouLU0hIiDZv3qyTJ0/q2WefVf369fV//s//kfTD7+LFxcVp9OjRev/995WTk6Pnn39eLVq0UGxsrCRp6dKlSk5O1vz58xUdHa05c+YoNjZWBQUFCgoKup6PCQAA3EbcDk1btmzR008/ra+++kqGYbis8/LyUkVFheVtZWZmusynp6crKChIeXl5LuErICBAISEhV9zGmjVrtH//fn366acKDg5W165d9dprr2nixImaMmWKfH19NX/+fLVt21YzZ86UJHXo0EGbNm3S7NmzzdA0a9YsjRw50nwo5/z585WRkaEFCxZo0qRJ1d63tLRUpaWl5rzT6bS83wAA4Nbj9um50aNHq0ePHtq7d69OnTql06dPm9OpU6duqJmSkhJJMu/Cq/L+++/r7rvvVqdOnZSSkqLvv//eXJebm6vOnTsrODjYXBYbGyun06l9+/aZNT9+TEJsbKxyc3MlSWVlZcrLy3Op8fb2VkxMjFnzY9OmTVNgYKA5hYWF3cCeAwAAT+f2SNPBgwf1wQcfKDw8vEYbqays1Lhx4/TQQw+pU6dO5vKnn35arVu3VmhoqHbv3q2JEyeqoKDAvAjd4XC4BCZJ5rzD4bhmjdPp1IULF3T69GlVVFRcseaLL764Yr8pKSlKTk42551OJ8EJAIDbmNuhKTo6WocOHarx0JSQkKC9e/dq06ZNLstHjRpl/rtz585q0aKF+vTpo8OHD+vee++t0R7c4efnJz8/vzp7fwAAcHO5HZpefPFFvfzyy3I4HOrcubPq16/vsj4yMtLtJhITE7Vq1Spt3LhRLVu2vGZtdHS0JOnQoUO69957FRISUu0ut6KiIkkyr4MKCQkxl11eY7PZ1KBBA/n4+MjHx+eKNVe7lgoAANxZ3A5NgwcPliSNGDHCXObl5SXDMNy+ENwwDL344otasWKF1q9fr7Zt2/7ka/Lz8yVJLVq0kCTZ7Xb96U9/UnFxsXmXW3Z2tmw2myIiIsya1atXu2wnOztbdrtdkuTr66uoqCjl5ORo4MCBkn44XZiTk6PExETL+wMAAG5fboemo0eP1tibJyQkaPHixfrnP/+pxo0bm9cgBQYGqkGDBjp8+LAWL16sxx9/XM2aNdPu3buVlJSkXr16mSNaffv2VUREhJ555hnNmDFDDodDkydPVkJCgnn6bPTo0Zo3b54mTJigESNGaO3atVq2bJkyMjLMXpKTkzVs2DD16NFDPXv21Jw5c3T+/HnzbjoAAHBnczs0tW7dusbe/O2335b0wwMsL7dw4UI999xz8vX11aeffmoGmLCwMA0ePFiTJ082a318fLRq1SqNGTNGdrtdDRs21LBhw1ye69S2bVtlZGQoKSlJc+fOVcuWLfXOO++YjxuQpCFDhuibb75RamqqHA6HunbtqszMzGoXhwMAgDvTdT3c8vDhw5ozZ44OHDggSYqIiNDYsWPdvjD7x895+rGwsDBt2LDhJ7fTunXraqfffqx3797atWvXNWsSExM5HQcAAK7I7ec0ZWVlKSIiQtu2bVNkZKQiIyO1detWdezYUdnZ2bXRIwAAQJ1ze6Rp0qRJSkpK0vTp06stnzhxon7xi1/UWHMAAACewu2RpgMHDig+Pr7a8hEjRmj//v010hQAAICncTs0NW/e3Lzt/3L5+fn8sC0AALhtuX16buTIkRo1apSOHDmiBx98UJL0+eef6/XXX3f5WREAAIDbiduh6ZVXXlHjxo01c+ZMpaSkSJJCQ0M1ZcoUvfTSSzXeIAAAgCdwOzR5eXkpKSlJSUlJOnv2rCSpcePGNd4YAACoPW0mZbjMH5seV0ed3DrcvqbpwoUL+v777yX9EJZOnTqlOXPmaM2aNTXeHAAAgKdwOzQNGDBA7733niTpzJkz6tmzp2bOnKkBAwaYT/gGAAC43bgdmnbu3KlHHnlEkvTBBx8oJCREX331ld577z29+eabNd4gAACAJ3A7NH3//ffmNUxr1qzRoEGD5O3trQceeEBfffVVjTcIAADgCdwOTeHh4fr44491/PhxZWVlqW/fvpKk4uJi2Wy2Gm8QAADAE7gdmlJTU/Xb3/5Wbdq0UXR0tOx2u6QfRp26detW4w0CAAB4ArcfOfBv//Zvevjhh3Xy5El16dLFXN6nTx/96le/qtHmAAAAPIXboUmSQkJCFBIS4rKsZ8+eNdIQAACAJ3L79BwAAMCdiNAEAABgAaEJAADAAkuhqXv37jp9+rQkaerUqebPqAAAANwpLIWmAwcO6Pz585KkP/zhDzp37lytNgUAAOBpLN0917VrVw0fPlwPP/ywDMPQG2+8oUaNGl2xNjU1tUYbBAAA8ASWQlN6erpeffVVrVq1Sl5eXvrkk09Ur171l3p5eRGaAADAbclSaGrXrp2WLFkiSfL29lZOTo6CgoJqtTEAAABP4vbDLSsrK2ujDwAAUEvaTMpwmT82Pa6OOrm1XdcTwQ8fPqw5c+bowIEDkqSIiAiNHTtW9957b402BwAA4Cncfk5TVlaWIiIitG3bNkVGRioyMlJbt25Vx44dlZ2dXRs9AgAA1Dm3R5omTZqkpKQkTZ8+vdryiRMn6he/+EWNNQcAAOAp3B5pOnDggOLj46stHzFihPbv318jTQEAAHgat0NT8+bNlZ+fX215fn4+d9QBAIDbltun50aOHKlRo0bpyJEjevDBByVJn3/+uV5//XUlJyfXeIMAAACewO3Q9Morr6hx48aaOXOmUlJSJEmhoaGaMmWKXnrppRpvEAAAwBO4HZq8vLyUlJSkpKQknT17VpLUuHHjGm8MAADAk1zXc5qqEJYAAMCdwu0LwWvStGnTdP/996tx48YKCgrSwIEDVVBQ4FJz8eJFJSQkqFmzZmrUqJEGDx6soqIil5rCwkLFxcUpICBAQUFBGj9+vMrLy11q1q9fr+7du8vPz0/h4eFKT0+v1k9aWpratGkjf39/RUdHa9u2bTW+zwAA4NZUp6Fpw4YNSkhI0JYtW5Sdna1Lly6pb9++On/+vFmTlJSklStXavny5dqwYYNOnDihQYMGmesrKioUFxensrIybd68WYsWLVJ6errLDwcfPXpUcXFxevTRR5Wfn69x48bp+eefV1ZWllmzdOlSJScn69VXX9XOnTvVpUsXxcbGqri4+OZ8GAAAwKPd0Om5G5WZmekyn56erqCgIOXl5alXr14qKSnRu+++q8WLF+uxxx6TJC1cuFAdOnTQli1b9MADD2jNmjXav3+/Pv30UwUHB6tr16567bXXNHHiRE2ZMkW+vr6aP3++2rZtq5kzZ0qSOnTooE2bNmn27NmKjY2VJM2aNUsjR47U8OHDJUnz589XRkaGFixYoEmTJt3ETwUAAHgit0aaLl26pD59+ujgwYO10kxJSYkkqWnTppKkvLw8Xbp0STExMWZN+/bt1apVK+Xm5kqScnNz1blzZwUHB5s1sbGxcjqd2rdvn1lz+Taqaqq2UVZWpry8PJcab29vxcTEmDU/VlpaKqfT6TIBAIDbl1uhqX79+tq9e3etNFJZWalx48bpoYceUqdOnSRJDodDvr6+atKkiUttcHCwHA6HWXN5YKpaX7XuWjVOp1MXLlzQt99+q4qKiivWVG3jx6ZNm6bAwEBzCgsLu74dBwAAtwS3r2n693//d7377rs13khCQoL27t2rJUuW1Pi2a0NKSopKSkrM6fjx43XdEgAAqEVuX9NUXl6uBQsW6NNPP1VUVJQaNmzosn7WrFluN5GYmKhVq1Zp48aNatmypbk8JCREZWVlOnPmjMtoU1FRkUJCQsyaH9/lVnV33eU1P77jrqioSDabTQ0aNJCPj498fHyuWFO1jR/z8/OTn5+f2/sKAABuTW6PNO3du1fdu3dX48aN9eWXX2rXrl3mdKXfpLsWwzCUmJioFStWaO3atWrbtq3L+qioKNWvX185OTnmsoKCAhUWFsput0uS7Ha79uzZ43KXW3Z2tmw2myIiIsyay7dRVVO1DV9fX0VFRbnUVFZWKicnx6wBAAB3NrdHmtatW1djb56QkKDFixfrn//8pxo3bmxePxQYGKgGDRooMDBQ8fHxSk5OVtOmTWWz2fTiiy/KbrfrgQcekCT17dtXEREReuaZZzRjxgw5HA5NnjxZCQkJ5kjQ6NGjNW/ePE2YMEEjRozQ2rVrtWzZMmVkZJi9JCcna9iwYerRo4d69uypOXPm6Pz58+bddAAA4M523Y8cOHTokA4fPqxevXqpQYMGMgxDXl5ebm3j7bffliT17t3bZfnChQv13HPPSZJmz54tb29vDR48WKWlpYqNjdVbb71l1vr4+GjVqlUaM2aM7Ha7GjZsqGHDhmnq1KlmTdu2bZWRkaGkpCTNnTtXLVu21DvvvGM+bkCShgwZom+++UapqalyOBzq2rWrMjMzq10cDgAA7kxuh6bvvvtOv/nNb7Ru3Tp5eXnp4MGDuueeexQfH6+77rrLfBaSFYZh/GSNv7+/0tLSlJaWdtWa1q1ba/Xq1dfcTu/evbVr165r1iQmJioxMfEnewIAwFO1mZThMn9selwddXL7cfuapqSkJNWvX1+FhYUKCAgwlw8ZMqTawyoBAABuF26PNK1Zs0ZZWVkud7lJ0n333aevvvqqxhoDAADwJG6PNJ0/f95lhKnKqVOnuAUfAADcttwOTY888ojee+89c97Ly0uVlZWaMWOGHn300RptDgAAwFO4fXpuxowZ6tOnj3bs2KGysjJNmDBB+/bt06lTp/T555/XRo8AAAB1zu2Rpk6dOunLL7/Uww8/rAEDBuj8+fMaNGiQdu3apXvvvbc2egQAAKhz1/WcpsDAQP3+97+v6V4AAAA81nWFptOnT+vdd9/VgQMHJEkREREaPny4mjZtWqPNAQAAeAq3T89t3LhRbdq00ZtvvqnTp0/r9OnTevPNN9W2bVtt3LixNnoEAACoc26PNCUkJGjIkCF6++235ePjI0mqqKjQf/zHfyghIUF79uyp8SYBAEB1PP375nJ7pOnQoUN6+eWXzcAk/fD7b8nJyTp06FCNNgcAAOAp3A5N3bt3N69lutyBAwfUpUuXGmkKAADA01g6Pbd7927z3y+99JLGjh2rQ4cO6YEHHpAkbdmyRWlpaZo+fXrtdAkAAFDHLIWmrl27ysvLS4ZhmMsmTJhQre7pp5/WkCFDaq47AAAAD2EpNB09erS2+wAAAPBolkJT69ata7sPAAAAj3ZdD7c8ceKENm3apOLiYlVWVrqse+mll2qkMQAAAE/idmhKT0/XCy+8IF9fXzVr1kxeXl7mOi8vL0ITAAC4Lbkdml555RWlpqYqJSVF3t5uP7EAAADgluR26vn+++/15JNPEpgAAMAdxe3kEx8fr+XLl9dGLwAAAB7L7dNz06ZN0y9/+UtlZmaqc+fOql+/vsv6WbNm1VhzAAAAnuK6QlNWVpbatWsnSdUuBAcAALgduR2aZs6cqQULFui5556rhXYAAAA8k9vXNPn5+emhhx6qjV4AAAA8ltuhaezYsfrLX/5SG70AAAB4LLdPz23btk1r167VqlWr1LFjx2oXgn/00Uc11hwAAICncDs0NWnSRIMGDaqNXgAAADyW26Fp4cKFtdEHAACAR+Ox3gAAABa4PdLUtm3baz6P6ciRIzfUEAAAqK7NpAyX+WPT4+qokzuX26Fp3LhxLvOXLl3Srl27lJmZqfHjx9dUXwAAAB7F7dA0duzYKy5PS0vTjh07brghAAAAT1Rj1zT1799fH374YU1tDgAAwKPUWGj64IMP1LRpU7des3HjRj3xxBMKDQ2Vl5eXPv74Y5f1zz33nLy8vFymfv36udScOnVKQ4cOlc1mU5MmTRQfH69z58651OzevVuPPPKI/P39FRYWphkzZlTrZfny5Wrfvr38/f3VuXNnrV692q19AQAAtze3T89169bN5UJwwzDkcDj0zTff6K233nJrW+fPn1eXLl00YsSIqz77qV+/fi6POfDz83NZP3ToUJ08eVLZ2dm6dOmShg8frlGjRmnx4sWSJKfTqb59+yomJkbz58/Xnj17NGLECDVp0kSjRo2SJG3evFlPPfWUpk2bpl/+8pdavHixBg4cqJ07d6pTp05u7RMAALg9uR2aBg4c6DLv7e2t5s2bq3fv3mrfvr1b2+rfv7/69+9/zRo/Pz+FhIRccd2BAweUmZmp7du3q0ePHpKkv/zlL3r88cf1xhtvKDQ0VO+//77Kysq0YMEC+fr6qmPHjsrPz9esWbPM0DR37lz169fPvJD9tddeU3Z2tubNm6f58+e7tU8AANwo7pTzTG6HpldffbU2+riq9evXKygoSHfddZcee+wx/fGPf1SzZs0kSbm5uWrSpIkZmCQpJiZG3t7e2rp1q371q18pNzdXvXr1kq+vr1kTGxur119/XadPn9Zdd92l3NxcJScnu7xvbGxstdOFlystLVVpaak573Q6a2iPAQCAJ/Loh1v269dP7733nnJycvT6669rw4YN6t+/vyoqKiRJDodDQUFBLq+pV6+emjZtKofDYdYEBwe71FTN/1RN1formTZtmgIDA80pLCzsxnYWAAB4NMsjTd7e3td8qKUkeXl5qby8/IabqvLkk0+a/+7cubMiIyN17733av369erTp0+Nvc/1SElJcRmdcjqdBCcAAG5jlkPTihUrrrouNzdXb775piorK2ukqau55557dPfdd+vQoUPq06ePQkJCVFxc7FJTXl6uU6dOmddBhYSEqKioyKWmav6naq52LZX0w7VWP74oHQAA3L4sh6YBAwZUW1ZQUKBJkyZp5cqVGjp0qKZOnVqjzf3Y119/re+++04tWrSQJNntdp05c0Z5eXmKioqSJK1du1aVlZWKjo42a37/+9/r0qVLql+/viQpOztb7dq101133WXW5OTkuDztPDs7W3a7vVb3BwAA3Dqu65qmEydOaOTIkercubPKy8uVn5+vRYsWqXXr1m5t59y5c8rPz1d+fr4k6ejRo8rPz1dhYaHOnTun8ePHa8uWLTp27JhycnI0YMAAhYeHKzY2VpLUoUMH9evXTyNHjtS2bdv0+eefKzExUU8++aRCQ0MlSU8//bR8fX0VHx+vffv2aenSpZo7d67LqbWxY8cqMzNTM2fO1BdffKEpU6Zox44dSkxMvJ6PBwAA3IbcCk0lJSWaOHGiwsPDtW/fPuXk5GjlypXX/SyjHTt2qFu3burWrZskKTk5Wd26dVNqaqp8fHy0e/du/e///b/1s5/9TPHx8YqKitJnn33mclrs/fffV/v27dWnTx89/vjjevjhh/W3v/3NXB8YGKg1a9bo6NGjioqK0ssvv6zU1FTzcQOS9OCDD2rx4sX629/+pi5duuiDDz7Qxx9/zDOaAACAyfLpuRkzZuj1119XSEiI/vGPf1zxdJ27evfuLcMwrro+KyvrJ7fRtGlT80GWVxMZGanPPvvsmjW//vWv9etf//on3w8AANyZLIemSZMmqUGDBgoPD9eiRYu0aNGiK9Z99NFHNdYcAAC3sx8/xFLiQZaezHJoevbZZ3/ykQMAAAC3K8uhKT09vRbbAAAA8Gwe/URwAAAAT0FoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWW754DAADX78fPZOJ5TLceRpoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALOCJ4AAA1DCe/n17YqQJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhQr64bAADgVtZmUobL/LHpcXXUCWpbnY40bdy4UU888YRCQ0Pl5eWljz/+2GW9YRhKTU1VixYt1KBBA8XExOjgwYMuNadOndLQoUNls9nUpEkTxcfH69y5cy41u3fv1iOPPCJ/f3+FhYVpxowZ1XpZvny52rdvL39/f3Xu3FmrV6+u8f0FAAC3rjoNTefPn1eXLl2UlpZ2xfUzZszQm2++qfnz52vr1q1q2LChYmNjdfHiRbNm6NCh2rdvn7Kzs7Vq1Spt3LhRo0aNMtc7nU717dtXrVu3Vl5env785z9rypQp+tvf/mbWbN68WU899ZTi4+O1a9cuDRw4UAMHDtTevXtrb+cBAMAtpU5Pz/Xv31/9+/e/4jrDMDRnzhxNnjxZAwYMkCS99957Cg4O1scff6wnn3xSBw4cUGZmprZv364ePXpIkv7yl7/o8ccf1xtvvKHQ0FC9//77Kisr04IFC+Tr66uOHTsqPz9fs2bNMsPV3Llz1a9fP40fP16S9Nprryk7O1vz5s3T/Pnzr9hfaWmpSktLzXmn01ljnwsAAPA8Hnsh+NGjR+VwOBQTE2MuCwwMVHR0tHJzcyVJubm5atKkiRmYJCkmJkbe3t7aunWrWdOrVy/5+vqaNbGxsSooKNDp06fNmsvfp6qm6n2uZNq0aQoMDDSnsLCwG99pAADgsTw2NDkcDklScHCwy/Lg4GBzncPhUFBQkMv6evXqqWnTpi41V9rG5e9xtZqq9VeSkpKikpISczp+/Li7uwgAAG4h3D13nfz8/OTn51fXbQAAgJvEY0eaQkJCJElFRUUuy4uKisx1ISEhKi4udllfXl6uU6dOudRcaRuXv8fVaqrWAwAAeGxoatu2rUJCQpSTk2Muczqd2rp1q+x2uyTJbrfrzJkzysvLM2vWrl2ryspKRUdHmzUbN27UpUuXzJrs7Gy1a9dOd911l1lz+ftU1VS9DwAA0g/PZLp8wp2lTkPTuXPnlJ+fr/z8fEk/XPydn5+vwsJCeXl5ady4cfrjH/+of/3rX9qzZ4+effZZhYaGauDAgZKkDh06qF+/fho5cqS2bdumzz//XImJiXryyScVGhoqSXr66afl6+ur+Ph47du3T0uXLtXcuXOVnJxs9jF27FhlZmZq5syZ+uKLLzRlyhTt2LFDiYmJN/sjAQAAHqpOr2nasWOHHn30UXO+KsgMGzZM6enpmjBhgs6fP69Ro0bpzJkzevjhh5WZmSl/f3/zNe+//74SExPVp08feXt7a/DgwXrzzTfN9YGBgVqzZo0SEhIUFRWlu+++W6mpqS7PcnrwwQe1ePFiTZ48Wb/73e9033336eOPP1anTp1uwqcAAACuxNOetl6noal3794yDOOq6728vDR16lRNnTr1qjVNmzbV4sWLr/k+kZGR+uyzz65Z8+tf/1q//vWvr90wAAC4Y3nsNU0AAACehNAEAABgAaEJAADAAkITAACABTwRHACAK/C0O7dQ9xhpAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAF/GAvAOCOx4/zwgpGmgAAACwgNAEAAFhAaAIAALCA0AQAAGABF4IDAO4oXPSN68VIEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFPBEcAHDb4unfqEkePdI0ZcoUeXl5uUzt27c311+8eFEJCQlq1qyZGjVqpMGDB6uoqMhlG4WFhYqLi1NAQICCgoI0fvx4lZeXu9SsX79e3bt3l5+fn8LDw5Wenn4zdg8AANxCPDo0SVLHjh118uRJc9q0aZO5LikpSStXrtTy5cu1YcMGnThxQoMGDTLXV1RUKC4uTmVlZdq8ebMWLVqk9PR0paammjVHjx5VXFycHn30UeXn52vcuHF6/vnnlZWVdVP3EwAAeDaPPz1Xr149hYSEVFteUlKid999V4sXL9Zjjz0mSVq4cKE6dOigLVu26IEHHtCaNWu0f/9+ffrppwoODlbXrl312muvaeLEiZoyZYp8fX01f/58tW3bVjNnzpQkdejQQZs2bdLs2bMVGxt7U/cVAAB4Lo8faTp48KBCQ0N1zz33aOjQoSosLJQk5eXl6dKlS4qJiTFr27dvr1atWik3N1eSlJubq86dOys4ONisiY2NldPp1L59+8yay7dRVVO1jaspLS2V0+l0mQAAdafNpAyXCahpHh2aoqOjlZ6erszMTL399ts6evSoHnnkEZ09e1YOh0O+vr5q0qSJy2uCg4PlcDgkSQ6HwyUwVa2vWnetGqfTqQsXLly1t2nTpikwMNCcwsLCbnR3AQCAB/Po03P9+/c3/x0ZGano6Gi1bt1ay5YtU4MGDeqwMyklJUXJycnmvNPpJDgBAHAb8+iRph9r0qSJfvazn+nQoUMKCQlRWVmZzpw541JTVFRkXgMVEhJS7W66qvmfqrHZbNcMZn5+frLZbC4TAAC4fd1SoencuXM6fPiwWrRooaioKNWvX185OTnm+oKCAhUWFsput0uS7Ha79uzZo+LiYrMmOztbNptNERERZs3l26iqqdoGAACA5OGh6be//a02bNigY8eOafPmzfrVr34lHx8fPfXUUwoMDFR8fLySk5O1bt065eXlafjw4bLb7XrggQckSX379lVERISeeeYZ/dd//ZeysrI0efJkJSQkyM/PT5I0evRoHTlyRBMmTNAXX3yht956S8uWLVNSUlJd7joAAPAwHn1N09dff62nnnpK3333nZo3b66HH35YW7ZsUfPmzSVJs2fPlre3twYPHqzS0lLFxsbqrbfeMl/v4+OjVatWacyYMbLb7WrYsKGGDRumqVOnmjVt27ZVRkaGkpKSNHfuXLVs2VLvvPMOjxsAAAAuPDo0LVmy5Jrr/f39lZaWprS0tKvWtG7dWqtXr77mdnr37q1du3ZdV48AAODO4NGhCQCAK+E35VAXPPqaJgAAAE9BaAIAALCA0AQAAGABoQkAAMACQhMAAIAF3D0HAKhVN3qnG3fKwVMQmgAAN92Pg5BEGILnIzQBADwGo0rwZIQmAECNIfTgdkZoAgD8pCuFIQIS7jTcPQcAAGABI00AABeMIAFXxkgTAACABYQmAAAACzg9BwC3kJo+dcapOMA6QhMA3IYIQ0DNIzQBwE3kTpgh+ACehdAEALXkZoUeq+9DCANuDKEJADwAgQbwfNw9BwAAYAEjTQBQAxgpAm5/hCYAcBMBCbgzcXoOAADAAkITAACABZyeA4Br4FQcgCqMNAEAAFhAaAIAALCA03MA8D84FQfgWghNAO5IBCQA7iI0AbjtEZAA1ASuaQIAALCAkSYAN4U7oz03MjLEqBKA2kJoAlDjrAaXH9ddq/ZG3gcAagKn534kLS1Nbdq0kb+/v6Kjo7Vt27a6bgmAfghIl08AcLMx0nSZpUuXKjk5WfPnz1d0dLTmzJmj2NhYFRQUKCgoqK7bAzwSoz0A7hSMNF1m1qxZGjlypIYPH66IiAjNnz9fAQEBWrBgQV23BgAA6hgjTf+jrKxMeXl5SklJMZd5e3srJiZGubm51epLS0tVWlpqzpeUlEiSnE5n7TdbSzq9muUyv/cPsTW+7Eb7uZG+b+S1N7ovP/W+7r63Jy2rLP3eZZnT6bzuZTf6+lt1mSSP6qculnlaP3wOdbvsWrU1rWqbhmH8dLEBwzAM47//+78NScbmzZtdlo8fP97o2bNntfpXX33VkMTExMTExMR0G0zHjx//yazASNN1SklJUXJysjlfWVmpU6dOqVmzZvLy8nJrW06nU2FhYTp+/LhsNltNt4rrwDHxTBwXz8Mx8UwcF+sMw9DZs2cVGhr6k7WEpv9x9913y8fHR0VFRS7Li4qKFBISUq3ez89Pfn5+LsuaNGlyQz3YbDb+y+1hOCaeiePieTgmnonjYk1gYKClOi4E/x++vr6KiopSTk6OuayyslI5OTmy2+112BkAAPAEjDRdJjk5WcOGDVOPHj3Us2dPzZkzR+fPn9fw4cPrujUAAFDHCE2XGTJkiL755hulpqbK4XCoa9euyszMVHBwcK2+r5+fn1599dVqp/tQdzgmnonj4nk4Jp6J41I7vAzDyj12AAAAdzauaQIAALCA0AQAAGABoQkAAMACQhMAAIAFhKYasnHjRj3xxBMKDQ2Vl5eXPv74Y5f1RUVFeu655xQaGqqAgAD169dPBw8eNNefOnVKL774otq1a6cGDRqoVatWeumll8zftKtSWFiouLg4BQQEKCgoSOPHj1d5efnN2MVbzo0ek8sZhqH+/ftfcTscE/fU1HHJzc3VY489poYNG8pms6lXr166cOGCuf7UqVMaOnSobDabmjRpovj4eJ07d662d++WVBPHxOFw6JlnnlFISIgaNmyo7t2768MPP3Sp4ZhYN23aNN1///1q3LixgoKCNHDgQBUUFLjUXLx4UQkJCWrWrJkaNWqkwYMHV3tAs5Xvp/Xr16t79+7y8/NTeHi40tPTa3v3blmEphpy/vx5denSRWlpadXWGYahgQMH6siRI/rnP/+pXbt2qXXr1oqJidH58+clSSdOnNCJEyf0xhtvaO/evUpPT1dmZqbi4+PN7VRUVCguLk5lZWXavHmzFi1apPT0dKWmpt60/byV3OgxudycOXOu+PM4HBP31cRxyc3NVb9+/dS3b19t27ZN27dvV2Jiory9//9X2tChQ7Vv3z5lZ2dr1apV2rhxo0aNGnVT9vFWUxPH5Nlnn1VBQYH+9a9/ac+ePRo0aJB+85vfaNeuXWYNx8S6DRs2KCEhQVu2bFF2drYuXbqkvn37unzmSUlJWrlypZYvX64NGzboxIkTGjRokLneyvfT0aNHFRcXp0cffVT5+fkaN26cnn/+eWVlVf9RcUj8YG8tkGSsWLHCnC8oKDAkGXv37jWXVVRUGM2bNzf+/ve/X3U7y5YtM3x9fY1Lly4ZhmEYq1evNry9vQ2Hw2HWvP3224bNZjNKS0trfkduIzdyTHbt2mX8r//1v4yTJ09W2w7H5MZc73GJjo42Jk+efNXt7t+/35BkbN++3Vz2ySefGF5eXsZ///d/1+xO3Gau95g0bNjQeO+991y21bRpU7OGY3JjiouLDUnGhg0bDMMwjDNnzhj169c3li9fbtYcOHDAkGTk5uYahmHt+2nChAlGx44dXd5ryJAhRmxsbG3v0i2JkaaboLS0VJLk7+9vLvP29pafn582bdp01deVlJTIZrOpXr0fnkGam5urzp07uzxsMzY2Vk6nU/v27aul7m9PVo/J999/r6efflppaWlX/A1CjknNsnJciouLtXXrVgUFBenBBx9UcHCwfv7zn7sct9zcXDVp0kQ9evQwl8XExMjb21tbt269SXtze7D6v5UHH3xQS5cu1alTp1RZWaklS5bo4sWL6t27tySOyY2qulSjadOmkqS8vDxdunRJMTExZk379u3VqlUr5ebmSrL2/ZSbm+uyjaqaqm3AFaHpJqj6L3JKSopOnz6tsrIyvf766/r666918uTJK77m22+/1WuvveYydO1wOKo9nbxq3uFw1N4O3IasHpOkpCQ9+OCDGjBgwBW3wzGpWVaOy5EjRyRJU6ZM0ciRI5WZmanu3burT58+5nU2DodDQUFBLtuuV6+emjZtynFxk9X/rSxbtkyXLl1Ss2bN5OfnpxdeeEErVqxQeHi4JI7JjaisrNS4ceP00EMPqVOnTpJ++Dx9fX2r/VB8cHCw+Xla+X66Wo3T6XS5RhA/IDTdBPXr19dHH32kL7/8Uk2bNlVAQIDWrVun/v37u1yDUcXpdCouLk4RERGaMmXKzW/4DmDlmPzrX//S2rVrNWfOnLpt9g5i5bhUVlZKkl544QUNHz5c3bp10+zZs9WuXTstWLCgLtu/LVn9/nrllVd05swZffrpp9qxY4eSk5P1m9/8Rnv27KnD7m8PCQkJ2rt3r5YsWVLXrdzx+O25myQqKkr5+fkqKSlRWVmZmjdvrujoaJehakk6e/as+vXrp8aNG2vFihWqX7++uS4kJETbtm1zqa+6U+JKp45wbT91TNauXavDhw9X+39ygwcP1iOPPKL169dzTGrBTx2XFi1aSJIiIiJcXtehQwcVFhZK+uGzLy4udllfXl6uU6dOcVyuw08dk8OHD2vevHnau3evOnbsKEnq0qWLPvvsM6WlpWn+/Pkck+uUmJhoXjTfsmVLc3lISIjKysp05swZl++ooqIi8/O08v0UEhJS7Y67oqIi2Ww2NWjQoDZ26ZbGSNNNFhgYqObNm+vgwYPasWOHy2kfp9Opvn37ytfXV//6179criGQJLvdrj179rh88WRnZ8tms1X7AwLrrnZMJk2apN27dys/P9+cJGn27NlauHChJI5JbbracWnTpo1CQ0Or3X795ZdfqnXr1pJ+OC5nzpxRXl6euX7t2rWqrKxUdHT0zduJ28zVjsn3338vSdVGzn18fMyRQY6JewzDUGJiolasWKG1a9eqbdu2LuujoqJUv3595eTkmMsKCgpUWFgou90uydr3k91ud9lGVU3VNvAjdX0l+u3i7Nmzxq5du4xdu3YZkoxZs2YZu3btMr766ivDMH64E27dunXG4cOHjY8//tho3bq1MWjQIPP1JSUlRnR0tNG5c2fj0KFDxsmTJ82pvLzcMAzDKC8vNzp16mT07dvXyM/PNzIzM43mzZsbKSkpdbLPnu5Gj8mV6Ed3FnFM3FcTx2X27NmGzWYzli9fbhw8eNCYPHmy4e/vbxw6dMis6devn9GtWzdj69atxqZNm4z77rvPeOqpp27qvt4qbvSYlJWVGeHh4cYjjzxibN261Th06JDxxhtvGF5eXkZGRoZZxzGxbsyYMUZgYKCxfv16l78H33//vVkzevRoo1WrVsbatWuNHTt2GHa73bDb7eZ6K99PR44cMQICAozx48cbBw4cMNLS0gwfHx8jMzPzpu7vrYLQVEPWrVtnSKo2DRs2zDAMw5g7d67RsmVLo379+karVq2MyZMnu9ySfrXXSzKOHj1q1h07dszo37+/0aBBA+Puu+82Xn75ZfORBHB1o8fkSn4cmgyDY+Kumjou06ZNM1q2bGkEBAQYdrvd+Oyzz1zWf/fdd8ZTTz1lNGrUyLDZbMbw4cONs2fP3oxdvOXUxDH58ssvjUGDBhlBQUFGQECAERkZWe0RBBwT667292DhwoVmzYULF4z/+I//MO666y4jICDA+NWvfmWcPHnSZTtWvp/WrVtndO3a1fD19TXuuecel/eAKy/DMIzaHMkCAAC4HXBNEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAdwzDMBQTE6PY2Nhq69566y01adJEX3/9dR10BuBWQGgCcMfw8vLSwoULtXXrVv31r381lx89elQTJkzQX/7yF7Vs2bJG3/PSpUs1uj0AdYfQBOCOEhYWprlz5+q3v/2tjh49KsMwFB8fr759+6pbt27q37+/GjVqpODgYD3zzDP69ttvzddmZmbq4YcfVpMmTdSsWTP98pe/1OHDh831x44dk5eXl5YuXaqf//zn8vf31/vvv18XuwmgFvCDvQDuSAMHDlRJSYkGDRqk1157Tfv27VPHjh31/PPP69lnn9WFCxc0ceJElZeXa+3atZKkDz/8UF5eXoqMjNS5c+eUmpqqY8eOKT8/X97e3jp27Jjatm2rNm3aaObMmerWrZv8/f3VokWLOt5bADWB0ATgjlRcXKyOHTvq1KlT+vDDD7V371599tlnysrKMmu+/vprhYWFqaCgQD/72c+qbePbb79V8+bNtWfPHnXq1MkMTXPmzNHYsWNv5u4AuAk4PQfgjhQUFKQXXnhBHTp00MCBA/Vf//VfWrdunRo1amRO7du3lyTzFNzBgwf11FNP6Z577pHNZlObNm0kSYWFhS7b7tGjx03dFwA3R726bgAA6kq9evVUr94PX4Pnzp3TE088oddff71aXdXptSeeeEKtW7fW3//+d4WGhqqyslKdOnVSWVmZS33Dhg1rv3kANx2hCQAkde/eXR9++KHatGljBqnLfffddyooKNDf//53PfLII5KkTZs23ew2AdQhTs8BgKSEhASdOnVKTz31lLZv367Dhw8rKytLw4cPV0VFhe666y41a9ZMf/vb33To0CGtXbtWycnJdd02gJuI0AQAkkJDQ/X555+roqJCffv2VefOnTVu3Dg1adJE3t7e8vb21pIlS5SXl6dOnTopKSlJf/7zn+u6bQA3EXfPAQAAWMBIEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAW/D8DoahTO4vmBAAAAABJRU5ErkJggg==","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["nsongs = {}\n","for y in range(1922,2012):\n","    nsongs[y] = len(data[data.year==y])\n","yrs = range(1922,2011)\n","values = [nsongs[y] for y in yrs]\n","plt.bar(yrs, values, align='center')\n","plt.xlabel(\"Year\")\n","plt.ylabel(\"Number of songs\")"]},{"cell_type":"code","execution_count":37,"metadata":{"trusted":true},"outputs":[],"source":["# separate input attributes and output into different dataframes\n","X = data.iloc[:,1:]\n","Y = data.iloc[:,0]\n","\n","# Train set\n","X_train = X.iloc[0:463715,:]\n","y_train = Y.iloc[0:463715]\n","\n","# Validation set\n","X_test = X.iloc[463715:,:]\n","y_test = Y.iloc[463715:]\n"]},{"cell_type":"markdown","metadata":{},"source":["Each of the features takes a wide range of different values and distributions.\n","\n","We apply MinMax scaling to our data."]},{"cell_type":"code","execution_count":38,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","\n","# Fit on training set only.\n","scaler.fit(X_train)\n","# Apply transform to both the train set and the test set.\n","X_train_scaled = scaler.transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","X_train = pd.DataFrame(X_train_scaled,columns=X_train.columns)\n","X_test = pd.DataFrame(X_test_scaled,columns=X_train.columns)"]},{"cell_type":"code","execution_count":39,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TimbreAvg1</th>\n","      <th>TimbreAvg2</th>\n","      <th>TimbreAvg3</th>\n","      <th>TimbreAvg4</th>\n","      <th>TimbreAvg5</th>\n","      <th>TimbreAvg6</th>\n","      <th>TimbreAvg7</th>\n","      <th>TimbreAvg8</th>\n","      <th>TimbreAvg9</th>\n","      <th>TimbreAvg10</th>\n","      <th>...</th>\n","      <th>TimbreCovariance69</th>\n","      <th>TimbreCovariance70</th>\n","      <th>TimbreCovariance71</th>\n","      <th>TimbreCovariance72</th>\n","      <th>TimbreCovariance73</th>\n","      <th>TimbreCovariance74</th>\n","      <th>TimbreCovariance75</th>\n","      <th>TimbreCovariance76</th>\n","      <th>TimbreCovariance77</th>\n","      <th>TimbreCovariance78</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>463715.000000</td>\n","      <td>463715.000000</td>\n","      <td>463715.000000</td>\n","      <td>463715.000000</td>\n","      <td>463715.000000</td>\n","      <td>463715.000000</td>\n","      <td>463715.000000</td>\n","      <td>463715.000000</td>\n","      <td>463715.000000</td>\n","      <td>463715.000000</td>\n","      <td>...</td>\n","      <td>463715.000000</td>\n","      <td>463715.000000</td>\n","      <td>463715.000000</td>\n","      <td>463715.000000</td>\n","      <td>463715.000000</td>\n","      <td>463715.000000</td>\n","      <td>463715.000000</td>\n","      <td>463715.000000</td>\n","      <td>463715.000000</td>\n","      <td>463715.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.691393</td>\n","      <td>0.469181</td>\n","      <td>0.496357</td>\n","      <td>0.350035</td>\n","      <td>0.395117</td>\n","      <td>0.358260</td>\n","      <td>0.515310</td>\n","      <td>0.397887</td>\n","      <td>0.477290</td>\n","      <td>0.426607</td>\n","      <td>...</td>\n","      <td>0.354631</td>\n","      <td>0.487984</td>\n","      <td>0.368845</td>\n","      <td>0.657332</td>\n","      <td>0.568014</td>\n","      <td>0.466481</td>\n","      <td>0.600205</td>\n","      <td>0.343815</td>\n","      <td>0.503517</td>\n","      <td>0.347715</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.100947</td>\n","      <td>0.071570</td>\n","      <td>0.056527</td>\n","      <td>0.036814</td>\n","      <td>0.051474</td>\n","      <td>0.063671</td>\n","      <td>0.040431</td>\n","      <td>0.044802</td>\n","      <td>0.038783</td>\n","      <td>0.063964</td>\n","      <td>...</td>\n","      <td>0.025093</td>\n","      <td>0.019768</td>\n","      <td>0.024255</td>\n","      <td>0.019886</td>\n","      <td>0.026819</td>\n","      <td>0.016738</td>\n","      <td>0.024350</td>\n","      <td>0.019045</td>\n","      <td>0.012446</td>\n","      <td>0.023989</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.634471</td>\n","      <td>0.431166</td>\n","      <td>0.464150</td>\n","      <td>0.328296</td>\n","      <td>0.363307</td>\n","      <td>0.314100</td>\n","      <td>0.492040</td>\n","      <td>0.371622</td>\n","      <td>0.455227</td>\n","      <td>0.384236</td>\n","      <td>...</td>\n","      <td>0.340913</td>\n","      <td>0.480545</td>\n","      <td>0.356429</td>\n","      <td>0.648426</td>\n","      <td>0.556221</td>\n","      <td>0.459283</td>\n","      <td>0.589716</td>\n","      <td>0.333782</td>\n","      <td>0.498175</td>\n","      <td>0.336685</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.705958</td>\n","      <td>0.479041</td>\n","      <td>0.499274</td>\n","      <td>0.345928</td>\n","      <td>0.396288</td>\n","      <td>0.350109</td>\n","      <td>0.516244</td>\n","      <td>0.398215</td>\n","      <td>0.477664</td>\n","      <td>0.425654</td>\n","      <td>...</td>\n","      <td>0.349484</td>\n","      <td>0.490259</td>\n","      <td>0.366313</td>\n","      <td>0.656434</td>\n","      <td>0.568816</td>\n","      <td>0.466181</td>\n","      <td>0.600938</td>\n","      <td>0.341908</td>\n","      <td>0.502698</td>\n","      <td>0.346333</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.765257</td>\n","      <td>0.517551</td>\n","      <td>0.530164</td>\n","      <td>0.367222</td>\n","      <td>0.427238</td>\n","      <td>0.393690</td>\n","      <td>0.539991</td>\n","      <td>0.424327</td>\n","      <td>0.500152</td>\n","      <td>0.468346</td>\n","      <td>...</td>\n","      <td>0.362847</td>\n","      <td>0.497755</td>\n","      <td>0.378403</td>\n","      <td>0.665694</td>\n","      <td>0.581546</td>\n","      <td>0.473821</td>\n","      <td>0.611202</td>\n","      <td>0.351684</td>\n","      <td>0.507992</td>\n","      <td>0.356798</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 90 columns</p>\n","</div>"],"text/plain":["          TimbreAvg1     TimbreAvg2     TimbreAvg3     TimbreAvg4  \\\n","count  463715.000000  463715.000000  463715.000000  463715.000000   \n","mean        0.691393       0.469181       0.496357       0.350035   \n","std         0.100947       0.071570       0.056527       0.036814   \n","min         0.000000       0.000000       0.000000       0.000000   \n","25%         0.634471       0.431166       0.464150       0.328296   \n","50%         0.705958       0.479041       0.499274       0.345928   \n","75%         0.765257       0.517551       0.530164       0.367222   \n","max         1.000000       1.000000       1.000000       1.000000   \n","\n","          TimbreAvg5     TimbreAvg6     TimbreAvg7     TimbreAvg8  \\\n","count  463715.000000  463715.000000  463715.000000  463715.000000   \n","mean        0.395117       0.358260       0.515310       0.397887   \n","std         0.051474       0.063671       0.040431       0.044802   \n","min         0.000000       0.000000       0.000000       0.000000   \n","25%         0.363307       0.314100       0.492040       0.371622   \n","50%         0.396288       0.350109       0.516244       0.398215   \n","75%         0.427238       0.393690       0.539991       0.424327   \n","max         1.000000       1.000000       1.000000       1.000000   \n","\n","          TimbreAvg9    TimbreAvg10  ...  TimbreCovariance69  \\\n","count  463715.000000  463715.000000  ...       463715.000000   \n","mean        0.477290       0.426607  ...            0.354631   \n","std         0.038783       0.063964  ...            0.025093   \n","min         0.000000       0.000000  ...            0.000000   \n","25%         0.455227       0.384236  ...            0.340913   \n","50%         0.477664       0.425654  ...            0.349484   \n","75%         0.500152       0.468346  ...            0.362847   \n","max         1.000000       1.000000  ...            1.000000   \n","\n","       TimbreCovariance70  TimbreCovariance71  TimbreCovariance72  \\\n","count       463715.000000       463715.000000       463715.000000   \n","mean             0.487984            0.368845            0.657332   \n","std              0.019768            0.024255            0.019886   \n","min              0.000000            0.000000            0.000000   \n","25%              0.480545            0.356429            0.648426   \n","50%              0.490259            0.366313            0.656434   \n","75%              0.497755            0.378403            0.665694   \n","max              1.000000            1.000000            1.000000   \n","\n","       TimbreCovariance73  TimbreCovariance74  TimbreCovariance75  \\\n","count       463715.000000       463715.000000       463715.000000   \n","mean             0.568014            0.466481            0.600205   \n","std              0.026819            0.016738            0.024350   \n","min              0.000000            0.000000            0.000000   \n","25%              0.556221            0.459283            0.589716   \n","50%              0.568816            0.466181            0.600938   \n","75%              0.581546            0.473821            0.611202   \n","max              1.000000            1.000000            1.000000   \n","\n","       TimbreCovariance76  TimbreCovariance77  TimbreCovariance78  \n","count       463715.000000       463715.000000       463715.000000  \n","mean             0.343815            0.503517            0.347715  \n","std              0.019045            0.012446            0.023989  \n","min              0.000000            0.000000            0.000000  \n","25%              0.333782            0.498175            0.336685  \n","50%              0.341908            0.502698            0.346333  \n","75%              0.351684            0.507992            0.356798  \n","max              1.000000            1.000000            1.000000  \n","\n","[8 rows x 90 columns]"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["X_train.describe()"]},{"cell_type":"markdown","metadata":{},"source":["90 features is lot of features and so we attempt dimensionality reduction by implementing PCA."]},{"cell_type":"markdown","metadata":{},"source":["# PCA"]},{"cell_type":"markdown","metadata":{},"source":["First we normalise our data using scikits StandardScalar.\n","This is a necessary step for pca:\n","> Principle Component Analysis (PCA) as being a prime example of when normalization is important. In PCA we are interested in the components that maximize the variance. If one component (e.g. human height) varies less than another (e.g. weight) because of their respective scales (meters vs. kilos), PCA might determine that the direction of maximal variance more closely corresponds with the ‘weight’ axis, if those features are not scaled. As a change in height of one meter can be considered much more important than the change in weight of one kilogram, this is clearly incorrect.\n","(https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html#sphx-glr-auto-examples-preprocessing-plot-scaling-importance-py)"]},{"cell_type":"code","execution_count":40,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","# Fit on training set only.\n","scaler.fit(X_train)\n","# Apply transform to both the train set and the test set.\n","X_train_std = scaler.transform(X_train)\n","X_test_std = scaler.transform(X_test)"]},{"cell_type":"code","execution_count":41,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TimbreAvg1</th>\n","      <th>TimbreAvg2</th>\n","      <th>TimbreAvg3</th>\n","      <th>TimbreAvg4</th>\n","      <th>TimbreAvg5</th>\n","      <th>TimbreAvg6</th>\n","      <th>TimbreAvg7</th>\n","      <th>TimbreAvg8</th>\n","      <th>TimbreAvg9</th>\n","      <th>TimbreAvg10</th>\n","      <th>...</th>\n","      <th>TimbreCovariance69</th>\n","      <th>TimbreCovariance70</th>\n","      <th>TimbreCovariance71</th>\n","      <th>TimbreCovariance72</th>\n","      <th>TimbreCovariance73</th>\n","      <th>TimbreCovariance74</th>\n","      <th>TimbreCovariance75</th>\n","      <th>TimbreCovariance76</th>\n","      <th>TimbreCovariance77</th>\n","      <th>TimbreCovariance78</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>4.637150e+05</td>\n","      <td>4.637150e+05</td>\n","      <td>4.637150e+05</td>\n","      <td>4.637150e+05</td>\n","      <td>4.637150e+05</td>\n","      <td>4.637150e+05</td>\n","      <td>4.637150e+05</td>\n","      <td>4.637150e+05</td>\n","      <td>4.637150e+05</td>\n","      <td>4.637150e+05</td>\n","      <td>...</td>\n","      <td>4.637150e+05</td>\n","      <td>4.637150e+05</td>\n","      <td>4.637150e+05</td>\n","      <td>4.637150e+05</td>\n","      <td>4.637150e+05</td>\n","      <td>4.637150e+05</td>\n","      <td>4.637150e+05</td>\n","      <td>4.637150e+05</td>\n","      <td>4.637150e+05</td>\n","      <td>4.637150e+05</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>7.593383e-16</td>\n","      <td>-2.120864e-15</td>\n","      <td>1.793384e-16</td>\n","      <td>-1.326988e-15</td>\n","      <td>-4.544139e-16</td>\n","      <td>2.359042e-15</td>\n","      <td>-5.413863e-16</td>\n","      <td>4.538010e-16</td>\n","      <td>-3.742449e-16</td>\n","      <td>1.892860e-15</td>\n","      <td>...</td>\n","      <td>2.297199e-16</td>\n","      <td>7.509414e-16</td>\n","      <td>-4.726175e-15</td>\n","      <td>-1.085286e-15</td>\n","      <td>-4.592805e-15</td>\n","      <td>-8.187235e-15</td>\n","      <td>-2.577913e-15</td>\n","      <td>-1.885015e-15</td>\n","      <td>-7.515972e-15</td>\n","      <td>4.761417e-15</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>1.000001e+00</td>\n","      <td>1.000001e+00</td>\n","      <td>1.000001e+00</td>\n","      <td>1.000001e+00</td>\n","      <td>1.000001e+00</td>\n","      <td>1.000001e+00</td>\n","      <td>1.000001e+00</td>\n","      <td>1.000001e+00</td>\n","      <td>1.000001e+00</td>\n","      <td>1.000001e+00</td>\n","      <td>...</td>\n","      <td>1.000001e+00</td>\n","      <td>1.000001e+00</td>\n","      <td>1.000001e+00</td>\n","      <td>1.000001e+00</td>\n","      <td>1.000001e+00</td>\n","      <td>1.000001e+00</td>\n","      <td>1.000001e+00</td>\n","      <td>1.000001e+00</td>\n","      <td>1.000001e+00</td>\n","      <td>1.000001e+00</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>-6.849083e+00</td>\n","      <td>-6.555536e+00</td>\n","      <td>-8.780881e+00</td>\n","      <td>-9.508272e+00</td>\n","      <td>-7.675981e+00</td>\n","      <td>-5.626720e+00</td>\n","      <td>-1.274530e+01</td>\n","      <td>-8.881098e+00</td>\n","      <td>-1.230653e+01</td>\n","      <td>-6.669490e+00</td>\n","      <td>...</td>\n","      <td>-1.413267e+01</td>\n","      <td>-2.468577e+01</td>\n","      <td>-1.520687e+01</td>\n","      <td>-3.305562e+01</td>\n","      <td>-2.117983e+01</td>\n","      <td>-2.786972e+01</td>\n","      <td>-2.464943e+01</td>\n","      <td>-1.805304e+01</td>\n","      <td>-4.045652e+01</td>\n","      <td>-1.449495e+01</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>-5.638876e-01</td>\n","      <td>-5.311584e-01</td>\n","      <td>-5.697513e-01</td>\n","      <td>-5.905186e-01</td>\n","      <td>-6.179717e-01</td>\n","      <td>-6.935698e-01</td>\n","      <td>-5.755554e-01</td>\n","      <td>-5.862542e-01</td>\n","      <td>-5.688679e-01</td>\n","      <td>-6.624309e-01</td>\n","      <td>...</td>\n","      <td>-5.466954e-01</td>\n","      <td>-3.763002e-01</td>\n","      <td>-5.118673e-01</td>\n","      <td>-4.478800e-01</td>\n","      <td>-4.397373e-01</td>\n","      <td>-4.299846e-01</td>\n","      <td>-4.307504e-01</td>\n","      <td>-5.268242e-01</td>\n","      <td>-4.292140e-01</td>\n","      <td>-4.598088e-01</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>1.442775e-01</td>\n","      <td>1.377638e-01</td>\n","      <td>5.161888e-02</td>\n","      <td>-1.115648e-01</td>\n","      <td>2.275066e-02</td>\n","      <td>-1.280171e-01</td>\n","      <td>2.309700e-02</td>\n","      <td>7.320083e-03</td>\n","      <td>9.665689e-03</td>\n","      <td>-1.489907e-02</td>\n","      <td>...</td>\n","      <td>-2.051342e-01</td>\n","      <td>1.151222e-01</td>\n","      <td>-1.043898e-01</td>\n","      <td>-4.517888e-02</td>\n","      <td>2.990574e-02</td>\n","      <td>-1.788398e-02</td>\n","      <td>3.008970e-02</td>\n","      <td>-1.001326e-01</td>\n","      <td>-6.574410e-02</td>\n","      <td>-5.763047e-02</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>7.317100e-01</td>\n","      <td>6.758454e-01</td>\n","      <td>5.980758e-01</td>\n","      <td>4.668744e-01</td>\n","      <td>6.240130e-01</td>\n","      <td>5.564446e-01</td>\n","      <td>6.104375e-01</td>\n","      <td>5.901695e-01</td>\n","      <td>5.894924e-01</td>\n","      <td>6.525343e-01</td>\n","      <td>...</td>\n","      <td>3.273959e-01</td>\n","      <td>4.942984e-01</td>\n","      <td>3.940738e-01</td>\n","      <td>4.204911e-01</td>\n","      <td>5.045541e-01</td>\n","      <td>4.385694e-01</td>\n","      <td>4.516087e-01</td>\n","      <td>4.131805e-01</td>\n","      <td>3.595684e-01</td>\n","      <td>3.786469e-01</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>3.057122e+00</td>\n","      <td>7.416766e+00</td>\n","      <td>8.909792e+00</td>\n","      <td>1.765551e+01</td>\n","      <td>1.175114e+01</td>\n","      <td>1.007897e+01</td>\n","      <td>1.198797e+01</td>\n","      <td>1.343956e+01</td>\n","      <td>1.347767e+01</td>\n","      <td>8.964296e+00</td>\n","      <td>...</td>\n","      <td>2.571906e+01</td>\n","      <td>2.590152e+01</td>\n","      <td>2.602152e+01</td>\n","      <td>1.723191e+01</td>\n","      <td>1.610766e+01</td>\n","      <td>3.187494e+01</td>\n","      <td>1.641892e+01</td>\n","      <td>3.445501e+01</td>\n","      <td>3.989141e+01</td>\n","      <td>2.719132e+01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 90 columns</p>\n","</div>"],"text/plain":["         TimbreAvg1    TimbreAvg2    TimbreAvg3    TimbreAvg4    TimbreAvg5  \\\n","count  4.637150e+05  4.637150e+05  4.637150e+05  4.637150e+05  4.637150e+05   \n","mean   7.593383e-16 -2.120864e-15  1.793384e-16 -1.326988e-15 -4.544139e-16   \n","std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00   \n","min   -6.849083e+00 -6.555536e+00 -8.780881e+00 -9.508272e+00 -7.675981e+00   \n","25%   -5.638876e-01 -5.311584e-01 -5.697513e-01 -5.905186e-01 -6.179717e-01   \n","50%    1.442775e-01  1.377638e-01  5.161888e-02 -1.115648e-01  2.275066e-02   \n","75%    7.317100e-01  6.758454e-01  5.980758e-01  4.668744e-01  6.240130e-01   \n","max    3.057122e+00  7.416766e+00  8.909792e+00  1.765551e+01  1.175114e+01   \n","\n","         TimbreAvg6    TimbreAvg7    TimbreAvg8    TimbreAvg9   TimbreAvg10  \\\n","count  4.637150e+05  4.637150e+05  4.637150e+05  4.637150e+05  4.637150e+05   \n","mean   2.359042e-15 -5.413863e-16  4.538010e-16 -3.742449e-16  1.892860e-15   \n","std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00   \n","min   -5.626720e+00 -1.274530e+01 -8.881098e+00 -1.230653e+01 -6.669490e+00   \n","25%   -6.935698e-01 -5.755554e-01 -5.862542e-01 -5.688679e-01 -6.624309e-01   \n","50%   -1.280171e-01  2.309700e-02  7.320083e-03  9.665689e-03 -1.489907e-02   \n","75%    5.564446e-01  6.104375e-01  5.901695e-01  5.894924e-01  6.525343e-01   \n","max    1.007897e+01  1.198797e+01  1.343956e+01  1.347767e+01  8.964296e+00   \n","\n","       ...  TimbreCovariance69  TimbreCovariance70  TimbreCovariance71  \\\n","count  ...        4.637150e+05        4.637150e+05        4.637150e+05   \n","mean   ...        2.297199e-16        7.509414e-16       -4.726175e-15   \n","std    ...        1.000001e+00        1.000001e+00        1.000001e+00   \n","min    ...       -1.413267e+01       -2.468577e+01       -1.520687e+01   \n","25%    ...       -5.466954e-01       -3.763002e-01       -5.118673e-01   \n","50%    ...       -2.051342e-01        1.151222e-01       -1.043898e-01   \n","75%    ...        3.273959e-01        4.942984e-01        3.940738e-01   \n","max    ...        2.571906e+01        2.590152e+01        2.602152e+01   \n","\n","       TimbreCovariance72  TimbreCovariance73  TimbreCovariance74  \\\n","count        4.637150e+05        4.637150e+05        4.637150e+05   \n","mean        -1.085286e-15       -4.592805e-15       -8.187235e-15   \n","std          1.000001e+00        1.000001e+00        1.000001e+00   \n","min         -3.305562e+01       -2.117983e+01       -2.786972e+01   \n","25%         -4.478800e-01       -4.397373e-01       -4.299846e-01   \n","50%         -4.517888e-02        2.990574e-02       -1.788398e-02   \n","75%          4.204911e-01        5.045541e-01        4.385694e-01   \n","max          1.723191e+01        1.610766e+01        3.187494e+01   \n","\n","       TimbreCovariance75  TimbreCovariance76  TimbreCovariance77  \\\n","count        4.637150e+05        4.637150e+05        4.637150e+05   \n","mean        -2.577913e-15       -1.885015e-15       -7.515972e-15   \n","std          1.000001e+00        1.000001e+00        1.000001e+00   \n","min         -2.464943e+01       -1.805304e+01       -4.045652e+01   \n","25%         -4.307504e-01       -5.268242e-01       -4.292140e-01   \n","50%          3.008970e-02       -1.001326e-01       -6.574410e-02   \n","75%          4.516087e-01        4.131805e-01        3.595684e-01   \n","max          1.641892e+01        3.445501e+01        3.989141e+01   \n","\n","       TimbreCovariance78  \n","count        4.637150e+05  \n","mean         4.761417e-15  \n","std          1.000001e+00  \n","min         -1.449495e+01  \n","25%         -4.598088e-01  \n","50%         -5.763047e-02  \n","75%          3.786469e-01  \n","max          2.719132e+01  \n","\n","[8 rows x 90 columns]"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["X_train_std = pd.DataFrame(X_train_std,columns=X_train.columns)\n","X_train_std.describe()"]},{"cell_type":"markdown","metadata":{},"source":["Our values are normalised and so we now actually apply PCA\n","(https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60)"]},{"cell_type":"code","execution_count":42,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["55"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.decomposition import PCA\n","# Make an instance of the Model\n","pca = PCA(.90)\n","\n","# We fit to only our training set\n","pca.fit(X_train_std)\n","# Print number of components generated\n","pca.n_components_"]},{"cell_type":"markdown","metadata":{},"source":["PCA(.90) means that scikit-learn choose the minimum number of principal components such that 90% of the variance is retained.\n","\n","In this case, 90% of the variance amounts to 55 principal components."]},{"cell_type":"code","execution_count":43,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/mountaintop/opt/anaconda3/envs/ML/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but PCA was fitted with feature names\n","  warnings.warn(\n"]}],"source":["X_train_proc = pca.transform(X_train_std)\n","X_test_proc = pca.transform(X_test_std)"]},{"cell_type":"code","execution_count":44,"metadata":{"trusted":true},"outputs":[],"source":["y_train_proc = y_train - min(y_train)\n","y_test_proc = y_test - min(y_test)\n","# y_train_proc"]},{"cell_type":"markdown","metadata":{},"source":["# Neural Network"]},{"cell_type":"code","execution_count":45,"metadata":{"trusted":true},"outputs":[],"source":["from tensorflow.python.keras import Sequential\n","from tensorflow.python.keras.layers import Dense, Lambda, Dropout\n","# from tensorflow.python.keras.initializers import Initializer\n","# from tensorflow.python.keras.utils import to_categorical\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.python.keras.callbacks import ReduceLROnPlateau, EarlyStopping"]},{"cell_type":"code","execution_count":46,"metadata":{"trusted":true},"outputs":[],"source":["y_train_hot = to_categorical(y_train_proc, 90)\n","y_test_hot = to_categorical(y_test_proc, 90)"]},{"cell_type":"code","execution_count":47,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(463715, 55)\n","(51630, 90)\n"]}],"source":["print(X_train_proc.shape)\n","print(y_test_hot.shape)"]},{"cell_type":"code","execution_count":48,"metadata":{"trusted":true},"outputs":[],"source":["def plot(history):\n","    epochs = range(1, len(history.history['loss']) + 1)\n","    plt.plot(epochs, history.history['mean_absolute_error'], label='train');\n","    plt.plot(epochs, history.history['val_mae'], label='val');\n","    plt.xlabel('epoch');\n","    plt.ylabel('mae');\n","    plt.legend();\n","    plt.show();"]},{"cell_type":"code","execution_count":49,"metadata":{"trusted":true},"outputs":[],"source":["model1 = Sequential()\n","model1.add(Dense(55, input_shape=(55,)))\n","model1.add(Dense(110))\n","model1.add(Dense(90, activation='softmax'))"]},{"cell_type":"code","execution_count":50,"metadata":{"trusted":true},"outputs":[],"source":["learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n","                                            patience=4, \n","                                            verbose=1, \n","                                            factor=0.5, \n","                                            min_lr=0.0001)"]},{"cell_type":"code","execution_count":51,"metadata":{"trusted":true},"outputs":[],"source":["model1.compile(optimizer='adam'\n","             , loss='categorical_crossentropy'\n","             , metrics=['accuracy'])"]},{"cell_type":"code","execution_count":52,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","7246/7246 [==============================] - 14s 2ms/step - loss: 3.3505 - accuracy: 0.0754 - val_loss: 3.8389 - val_accuracy: 0.0078\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","Epoch 2/5\n","7246/7246 [==============================] - 14s 2ms/step - loss: 3.3129 - accuracy: 0.0765 - val_loss: 3.8399 - val_accuracy: 0.0066\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","Epoch 3/5\n","7246/7246 [==============================] - 10s 1ms/step - loss: 3.3095 - accuracy: 0.0772 - val_loss: 3.8318 - val_accuracy: 0.0067\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","Epoch 4/5\n","7246/7246 [==============================] - 16s 2ms/step - loss: 3.3078 - accuracy: 0.0774 - val_loss: 3.8345 - val_accuracy: 0.0099\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","Epoch 5/5\n","7246/7246 [==============================] - 10s 1ms/step - loss: 3.3065 - accuracy: 0.0779 - val_loss: 3.8498 - val_accuracy: 0.0066\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"]}],"source":["fit1 = model1.fit(x=X_train_proc, y=y_train_hot\n","          , epochs=5\n","          , batch_size=64\n","          , validation_data=(X_test_proc, y_test_hot)\n","          , callbacks=[learning_rate_reduction])"]},{"cell_type":"code","execution_count":53,"metadata":{"trusted":true},"outputs":[],"source":["# plot(fit1)"]},{"cell_type":"code","execution_count":54,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_5 (Dense)              (None, 55)                3080      \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 110)               6160      \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 90)                9990      \n","=================================================================\n","Total params: 19,230\n","Trainable params: 19,230\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model1.summary()"]},{"cell_type":"code","execution_count":55,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/mountaintop/opt/anaconda3/envs/ML/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:454: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"]}],"source":["preds = model1.predict_classes(X_test_proc)"]},{"cell_type":"code","execution_count":56,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[80 76 78 ... 79 79 78]\n","[83 85 85 ... 83 85 85]\n"]},{"data":{"text/plain":["12.248770094906062"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["print(np.array(y_test_proc))\n","print(preds)\n","np.mean(np.absolute((preds-np.array(y_test_proc))))"]},{"cell_type":"code","execution_count":57,"metadata":{"trusted":true},"outputs":[],"source":["model2 = Sequential()\n","model2.add(Dense(55, input_shape=(55,), activation='relu'))\n","model2.add(Dense(1))"]},{"cell_type":"code","execution_count":58,"metadata":{"trusted":true},"outputs":[],"source":["learning_rate_reduction1 = ReduceLROnPlateau(monitor='mean_absolute_error', \n","                                            patience=2, \n","                                            verbose=1, \n","                                            factor=0.5, \n","                                            min_lr=0.0001)"]},{"cell_type":"code","execution_count":59,"metadata":{"trusted":true},"outputs":[],"source":["model2.compile(optimizer='adam'\n","             , loss='mse'\n","             , metrics=['mae'])"]},{"cell_type":"code","execution_count":60,"metadata":{"_kg_hide-output":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","7246/7246 [==============================] - 10s 1ms/step - loss: 457.3153 - mae: 13.9047 - val_loss: 127.2818 - val_mae: 7.8621\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n","Epoch 2/10\n","7246/7246 [==============================] - 7s 1ms/step - loss: 96.2795 - mae: 7.1914 - val_loss: 118.7002 - val_mae: 7.5930\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n","Epoch 3/10\n","7246/7246 [==============================] - 6s 845us/step - loss: 92.7615 - mae: 7.0101 - val_loss: 117.9895 - val_mae: 7.6104\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n","Epoch 4/10\n","7246/7246 [==============================] - 6s 837us/step - loss: 91.3879 - mae: 6.9440 - val_loss: 117.1054 - val_mae: 7.5728\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n","Epoch 5/10\n","7246/7246 [==============================] - 6s 845us/step - loss: 90.5329 - mae: 6.8990 - val_loss: 119.4989 - val_mae: 7.6751\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n","Epoch 6/10\n","7246/7246 [==============================] - 7s 976us/step - loss: 90.0653 - mae: 6.8755 - val_loss: 117.3770 - val_mae: 7.5657\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n","Epoch 7/10\n","7246/7246 [==============================] - 8s 1ms/step - loss: 89.6169 - mae: 6.8521 - val_loss: 121.7897 - val_mae: 7.7292\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n","Epoch 8/10\n","7246/7246 [==============================] - 10s 1ms/step - loss: 89.3299 - mae: 6.8400 - val_loss: 114.7935 - val_mae: 7.4835\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n","Epoch 9/10\n","7246/7246 [==============================] - 7s 996us/step - loss: 89.1124 - mae: 6.8267 - val_loss: 112.8238 - val_mae: 7.4117\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n","Epoch 10/10\n","7246/7246 [==============================] - 7s 959us/step - loss: 88.8935 - mae: 6.8158 - val_loss: 115.9546 - val_mae: 7.4448\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n"]}],"source":["fit2 = model2.fit(x=X_train_proc, y=y_train_proc\n","          , epochs=10\n","          , batch_size=64\n","          , validation_data=(X_test_proc, y_test_proc)\n","          , callbacks=[learning_rate_reduction1])"]},{"cell_type":"code","execution_count":61,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["7.4447795803639725"]},"execution_count":61,"metadata":{},"output_type":"execute_result"}],"source":["preds_model_rms = model2.predict(X_test_proc)\n","np.mean(np.absolute(preds_model_rms.T-np.array(y_test_proc)))"]},{"cell_type":"code","execution_count":63,"metadata":{"trusted":true},"outputs":[],"source":["#plot(fit2)"]},{"cell_type":"code","execution_count":64,"metadata":{"trusted":true},"outputs":[],"source":["# from sklearn.metrics import mean_squared_error, r2_score\n","# mean_squared_error(predictions_linearRegr, np.array(y_test_proc))\n","es = EarlyStopping(monitor='val_mae', patience=2, restore_best_weights=True)"]},{"cell_type":"code","execution_count":65,"metadata":{"trusted":true},"outputs":[],"source":["model3 = Sequential()\n","model3.add(Dense(55, input_shape=(55,), activation='relu'))\n","model3.add(Dense(110, activation='relu'))\n","model3.add(Dropout(0.2))\n","model3.add(Dense(1))\n","\n","model3.compile(optimizer='adam'\n","             , loss='mse'\n","             , metrics=['mae'])"]},{"cell_type":"code","execution_count":66,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","7246/7246 [==============================] - 13s 2ms/step - loss: 212.4924 - mae: 10.1954 - val_loss: 113.7957 - val_mae: 7.5687\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n","Epoch 2/10\n","7246/7246 [==============================] - 9s 1ms/step - loss: 114.5727 - mae: 8.0913 - val_loss: 117.0780 - val_mae: 7.6122\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n","Epoch 3/10\n","7246/7246 [==============================] - 11s 1ms/step - loss: 110.7463 - mae: 7.9395 - val_loss: 125.3980 - val_mae: 8.0199\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n"]}],"source":["fit3 = model3.fit(x=X_train_proc, y=y_train_proc\n","          , epochs=10\n","          , batch_size=64\n","          , validation_data=(X_test_proc, y_test_proc)\n","          , callbacks=[learning_rate_reduction1, es])"]},{"cell_type":"code","execution_count":67,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["7.568682176115992"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["preds_model_rms = model3.predict(X_test_proc)\n","np.mean(np.absolute(preds_model_rms.T-np.array(y_test_proc)))"]},{"cell_type":"code","execution_count":69,"metadata":{"trusted":true},"outputs":[],"source":["# plot(fit3)"]},{"cell_type":"markdown","metadata":{},"source":["batch size = 64"]},{"cell_type":"code","execution_count":70,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","3623/3623 [==============================] - 11s 2ms/step - loss: 114.1634 - mae: 8.0726 - val_loss: 113.5695 - val_mae: 7.3671\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n","Epoch 2/10\n","3623/3623 [==============================] - 5s 1ms/step - loss: 110.9770 - mae: 7.9487 - val_loss: 118.6324 - val_mae: 7.6473\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n","Epoch 3/10\n","3623/3623 [==============================] - 5s 1ms/step - loss: 109.3349 - mae: 7.8738 - val_loss: 111.9418 - val_mae: 7.3480\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n","Epoch 4/10\n","3623/3623 [==============================] - 5s 1ms/step - loss: 108.0007 - mae: 7.8149 - val_loss: 114.8246 - val_mae: 7.4546\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n","Epoch 5/10\n","3623/3623 [==============================] - 7s 2ms/step - loss: 107.0107 - mae: 7.7742 - val_loss: 114.1630 - val_mae: 7.4031\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n"]}],"source":["model3.compile(optimizer='adam'\n","             , loss='mse'\n","             , metrics=['mae'])\n","fit3 = model3.fit(x=X_train_proc, y=y_train_proc\n","          , epochs=10\n","          , batch_size=128\n","          , validation_data=(X_test_proc, y_test_proc)\n","          , callbacks=[learning_rate_reduction1, es])"]},{"cell_type":"code","execution_count":71,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["7.347981547552002"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["preds_model_rms = model3.predict(X_test_proc)\n","np.mean(np.absolute(preds_model_rms.T-np.array(y_test_proc)))"]},{"cell_type":"code","execution_count":73,"metadata":{"trusted":true},"outputs":[],"source":["# plot(fit3)"]},{"cell_type":"markdown","metadata":{},"source":["batch size = 128"]},{"cell_type":"code","execution_count":74,"metadata":{"trusted":true},"outputs":[],"source":["from keras.optimizers import RMSprop\n","# adam = optimizers.Adam()"]},{"cell_type":"code","execution_count":86,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","7246/7246 [==============================] - 13s 2ms/step - loss: 105.7650 - mae: 7.7009 - val_loss: 142.0077 - val_mae: 8.7068\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n","Epoch 2/10\n","7246/7246 [==============================] - 9s 1ms/step - loss: 104.7887 - mae: 7.6626 - val_loss: 109.4881 - val_mae: 7.2984\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n","Epoch 3/10\n","7246/7246 [==============================] - 8s 1ms/step - loss: 104.0545 - mae: 7.6244 - val_loss: 106.0850 - val_mae: 7.1266\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n","Epoch 4/10\n","7246/7246 [==============================] - 8s 1ms/step - loss: 103.5567 - mae: 7.5961 - val_loss: 108.5569 - val_mae: 7.3047\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n","Epoch 5/10\n","7246/7246 [==============================] - 8s 1ms/step - loss: 102.5428 - mae: 7.5541 - val_loss: 110.0489 - val_mae: 7.2418\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mean_absolute_error` which is not available. Available metrics are: loss,mae,val_loss,val_mae,lr\n"]}],"source":["model3.compile(optimizer='RMSprop'\n","             , loss='mse'\n","             , metrics=['mae'])\n","fit4 = model3.fit(x=X_train_proc, y=y_train_proc\n","          , epochs=10\n","          , batch_size=64\n","          , validation_data=(X_test_proc, y_test_proc\n","          , callbacks=[learning_rate_reduction1, es])"]},{"cell_type":"code","execution_count":87,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["7.126585005753358"]},"execution_count":87,"metadata":{},"output_type":"execute_result"}],"source":["preds_model_rms = model3.predict(X_test_proc)\n","np.mean(np.absolute(preds_model_rms.T-np.array(y_test_proc)))"]},{"cell_type":"code","execution_count":88,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","cm = confusion_matrix(np.round_(np.array(preds_model_rms), decimals=-1), np.round_(np.array(y_test_proc), decimals=-1))"]},{"cell_type":"code","execution_count":89,"metadata":{"trusted":true},"outputs":[{"ename":"ValueError","evalue":"Shape of passed values is (12, 12), indices imply (11, 11)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn [89], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[1;32m      2\u001b[0m ind \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39m1920\u001b[39m,\u001b[39m2030\u001b[39m,\u001b[39m10\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m df_heat \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(cm, index\u001b[39m=\u001b[39;49mind, columns\u001b[39m=\u001b[39;49mind)\n\u001b[1;32m      4\u001b[0m \u001b[39mlen\u001b[39m(ind)\n\u001b[1;32m      5\u001b[0m \u001b[39m# lab = pd.unique(df_heat[0])\u001b[39;00m\n","File \u001b[0;32m~/opt/anaconda3/envs/ML/lib/python3.9/site-packages/pandas/core/frame.py:720\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    710\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    711\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    712\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    717\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    718\u001b[0m         )\n\u001b[1;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    721\u001b[0m             data,\n\u001b[1;32m    722\u001b[0m             index,\n\u001b[1;32m    723\u001b[0m             columns,\n\u001b[1;32m    724\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    725\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    726\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[1;32m    727\u001b[0m         )\n\u001b[1;32m    729\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    730\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n","File \u001b[0;32m~/opt/anaconda3/envs/ML/lib/python3.9/site-packages/pandas/core/internals/construction.py:349\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    345\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[1;32m    346\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[1;32m    347\u001b[0m )\n\u001b[0;32m--> 349\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[1;32m    351\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    353\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n","File \u001b[0;32m~/opt/anaconda3/envs/ML/lib/python3.9/site-packages/pandas/core/internals/construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    418\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[1;32m    419\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[0;32m--> 420\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n","\u001b[0;31mValueError\u001b[0m: Shape of passed values is (12, 12), indices imply (11, 11)"]}],"source":["import seaborn as sns\n","ind = list(range(1920,2030,10))\n","df_heat = pd.DataFrame(cm, index=ind, columns=ind)\n","len(ind)\n","# lab = pd.unique(df_heat[0])\n","sns.heatmap(df_heat)\n","df_heat\n","# df_plot.transpose().corr()\n","# cm.shape"]}],"metadata":{"kernelspec":{"display_name":"ML","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13 (main, Oct 13 2022, 16:12:30) \n[Clang 12.0.0 ]"},"vscode":{"interpreter":{"hash":"527e1f183729315cc0b20e076f8fa01a9ad5031799e510482f8c5a1d9432ab9a"}}},"nbformat":4,"nbformat_minor":4}
